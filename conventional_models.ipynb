{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model(trainX, trainy, testX, testy, model):\n",
    "    model.fit(trainX, trainy)\n",
    "    y_predictions = model.predict(testX)\n",
    "    y_pred_prob = model.predict_proba(testX)\n",
    "    y_pred_prob = y_pred_prob[:, 1]\n",
    "    return measurements(testy, y_predictions, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurements(y_test, y_pred, y_pred_prob):  \n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    sensitivity = metrics.recall_score(y_test, y_pred)\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = TN/(TN+FP)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    mcc = metrics.matthews_corrcoef(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    return [sensitivity, specificity, precision, acc, mcc, auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(model_name, purpose, result):\n",
    "    print('\\033[1mOptimized {} model {} performance: \\033[0m'.format(model_name, purpose))\n",
    "    print(\"Accuracy:    {0:.3f}\".format(result[3]))\n",
    "    print(\"AUC:         {0:.3f}\".format(result[5]))\n",
    "    print(\"Sensitivity: {0:.3f}\".format(result[0]))\n",
    "    print(\"Specificity: {0:.3f}\".format(result[1]))\n",
    "    print(\"Precision:   {0:.3f}\".format(result[2]))\n",
    "    print(\"MCC:         {0:.3f}\".format(result[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset\n",
    "#### Data is used for  training and validation\n",
    "#### Test is only used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'''C:\\Users\\Ting.Li\\Documents\\2019\\projects\\L1000\\data\\github\\data.csv''', low_memory=False)\n",
    "test = pd.read_csv(r'''C:\\Users\\Ting.Li\\Documents\\2019\\projects\\L1000\\data\\github\\testing.csv''', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,3:].values\n",
    "y = data.loc[:,'DILIst.1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names =  ['Group', 'model','sensitivity','specificity', 'precision', 'acc', 'mcc', 'auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define a dataframe to save the training performance\n",
    "training_metrics  = pd.DataFrame(columns = col_names)\n",
    "\n",
    "for k in [3,5,7,9,11]:  \n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    for j in range(100):\n",
    "        print(k, j)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.2, random_state=j)\n",
    "        result = single_model(trainX=X_train, trainy=y_train, testX=X_test, testy=y_test, model=model)\n",
    "        training_metrics.loc[len(training_metrics)] = [str(j), 'knn_k'+str(k),result[0], result[1], result[2], result[3],  result[4], result[5]]\n",
    "\n",
    "training_metrics.to_csv(r'''C:\\Users\\Ting.Li\\Documents\\2019\\projects\\L1000\\data\\github\\knn_training_metrics_all.csv''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define a dataframe to save the training performance\n",
    "training_metrics  = pd.DataFrame(columns = col_names)\n",
    "\n",
    "import itertools\n",
    "kernels = ['poly', 'rbf']\n",
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "gammas = [0.1, 0.01, 0.001, 0.0001]\n",
    "paras = [l for l in itertools.product(kernels, Cs, gammas)]\n",
    "\n",
    "\n",
    "for i in range(len(paras)):\n",
    "    para=paras[i]\n",
    "    kernel, C, gamma = para[0], para[1], para[2]\n",
    "    model = SVC(C=C, kernel=kernel, gamma=gamma, probability=True)\n",
    "    for j in range(100):\n",
    "        name = 'svm_'+'paras_'+str(i)+'_kernel_'+para[0]+'_C_'+str(para[1])+'_gamma_'+str(para[2])\n",
    "        print(i, j)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.2, random_state=j)\n",
    "        result = single_model(trainX=X_train, trainy=y_train, testX=X_test, testy=y_test, model=model)\n",
    "        training_metrics.loc[len(training_metrics)] = [str(j), name, result[0], result[1], result[2], result[3],  result[4], result[5]]\n",
    "\n",
    "training_metrics.to_csv(r'''C:\\Users\\Ting.Li\\Documents\\2019\\projects\\L1000\\data\\github\\svm_training_metrics_all.csv''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define a dataframe to save the training performance\n",
    "training_metrics  = pd.DataFrame(columns = col_names)\n",
    "\n",
    "n_estimators = [100, 200, 300, 400, 500]\n",
    "max_depth = [8, 10, 12]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "paras = [l for l in itertools.product(n_estimators, max_depth, min_samples_split, min_samples_leaf)]\n",
    "\n",
    "for i in range(len(paras)):\n",
    "    para = paras[i]\n",
    "    n_estimator, depth, samples_split, samples_leaf = para[0], para[1], para[2], para[3]\n",
    "    model = RandomForestClassifier(n_estimators=n_estimator, max_depth=depth, min_samples_split=samples_split, min_samples_leaf=samples_leaf, random_state=7)\n",
    "\n",
    "    for j in range(100):\n",
    "        print(i, j)\n",
    "        name = 'rf_'+'_paras_'+str(i)+'_n_'+str(n_estimator)+'_depth_'+str(depth)+'_split_'+str(samples_split) + '_leaf_' + str(samples_leaf)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.2, random_state=j)\n",
    "        result = single_model(trainX=X_train, trainy=y_train, testX=X_test, testy=y_test, model=model)\n",
    "        training_metrics.loc[len(training_metrics)] = [str(j), name, result[0], result[1], result[2], result[3],  result[4], result[5]]\n",
    "\n",
    "training_metrics.to_csv(r'''C:\\Users\\Ting.Li\\Documents\\2019\\projects\\L1000\\data\\github\\rf_training_metrics_all.csv''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOptimized KNN model training performance: \u001b[0m\n",
      "Accuracy:    0.735\n",
      "AUC:         0.762\n",
      "Sensitivity: 0.834\n",
      "Specificity: 0.591\n",
      "Precision:   0.750\n",
      "MCC:         0.441\n",
      "\u001b[1mOptimized KNN model testing performance: \u001b[0m\n",
      "Accuracy:    0.721\n",
      "AUC:         0.764\n",
      "Sensitivity: 0.821\n",
      "Specificity: 0.574\n",
      "Precision:   0.739\n",
      "MCC:         0.409\n"
     ]
    }
   ],
   "source": [
    "### KNN\n",
    "optimized_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.2, random_state=51)\n",
    "### Optimized KNN model training performance\n",
    "print_result('KNN', 'training', single_model(X_train, y_train, X_test, y_test, optimized_knn))\n",
    "### Optimized KNN model testing performance\n",
    "print_result('KNN', 'testing', single_model(X_train, y_train, test.iloc[:, 3:].values, test.loc[:,'DILIst.1'].values, optimized_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOptimized SVM model training performance: \u001b[0m\n",
      "Accuracy:    0.753\n",
      "AUC:         0.778\n",
      "Sensitivity: 0.856\n",
      "Specificity: 0.602\n",
      "Precision:   0.759\n",
      "MCC:         0.478\n",
      "\u001b[1mOptimized SVM model testing performance: \u001b[0m\n",
      "Accuracy:    0.743\n",
      "AUC:         0.777\n",
      "Sensitivity: 0.888\n",
      "Specificity: 0.529\n",
      "Precision:   0.735\n",
      "MCC:         0.455\n"
     ]
    }
   ],
   "source": [
    "### SVM\n",
    "optimized_svm = SVC(C=10, kernel='rbf', gamma=0.0001, probability=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.2, random_state=78)\n",
    "### Optimized SVM model training performance\n",
    "print_result('SVM', 'training', single_model(X_train, y_train, X_test, y_test, optimized_svm))\n",
    "### Optimized SVM model testing performance\n",
    "print_result('SVM', 'testing', single_model(X_train, y_train, test.iloc[:, 3:].values, test.loc[:,'DILIst.1'].values, optimized_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOptimized RF model training performance: \u001b[0m\n",
      "Accuracy:    0.774\n",
      "AUC:         0.771\n",
      "Sensitivity: 0.977\n",
      "Specificity: 0.476\n",
      "Precision:   0.732\n",
      "MCC:         0.549\n",
      "\u001b[1mOptimized RF model testing performance: \u001b[0m\n",
      "Accuracy:    0.752\n",
      "AUC:         0.747\n",
      "Sensitivity: 0.975\n",
      "Specificity: 0.424\n",
      "Precision:   0.713\n",
      "MCC:         0.502\n"
     ]
    }
   ],
   "source": [
    "### RF\n",
    "optimized_rf = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=5,min_samples_leaf=1, random_state=7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.2, random_state=9)\n",
    "### Optimized KNN model training performance\n",
    "print_result('RF', 'training', single_model(X_train, y_train, X_test, y_test, optimized_rf))\n",
    "### Optimized KNN model testing performance\n",
    "print_result('RF', 'testing', single_model(X_train, y_train, test.iloc[:, 3:].values, test.loc[:,'DILIst.1'].values, optimized_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
